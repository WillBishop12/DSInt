{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Will\\Anaconda2\\lib\\site-packages\\matplotlib\\__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "#Initial commands\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before next step, make sure lines in CSV file are randomly shuffled.  Use code from http://stackoverflow.com/questions/4618298/randomly-mix-lines-of-3-million-line-file.  But make sure to keep the first line intact so you don't forget the column names!\n",
    "\n",
    "Code needs to modified in the following way: <br>\n",
    "data = lines[1:] <br>\n",
    "newlines = [lines[0]] + data <br>\n",
    "write(newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import data in batches instead of all at once\n",
    "\n",
    "OnTimeDataFrames = []\n",
    "for n in range(15):\n",
    "    #100,001 rows total: 100,000 of data, plus first row for column names!  Easy to mess up...\n",
    "    #Note we aren't using lat/long data in the model at the present time, but can change this later\n",
    "    OnTimeDataFrames.append(pd.read_csv('Sample_2011_2016_carr_mark.csv', nrows=100001,\n",
    "                                        skiprows=range(1, 1 + 100000*n) if n > 0 else None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(100001, 68)\n",
      "(90434, 68)\n"
     ]
    }
   ],
   "source": [
    "#Check shapes of all data frames - all except the last should have 100,000 rows, all should have same no. of columns\n",
    "for X in OnTimeDataFrames: print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'Year', u'Quarter', u'Month', u'DayofMonth',\n",
       "       u'DayOfWeek', u'FlightDate', u'UniqueCarrier', u'AirlineID', u'Carrier',\n",
       "       u'TailNum', u'FlightNum', u'OriginAirportID', u'OriginAirportSeqID',\n",
       "       u'OriginCityMarketID', u'Origin', u'OriginCityName', u'OriginState',\n",
       "       u'OriginStateFips', u'OriginStateName', u'OriginWac', u'DestAirportID',\n",
       "       u'DestAirportSeqID', u'DestCityMarketID', u'Dest', u'DestCityName',\n",
       "       u'DestState', u'DestStateFips', u'DestStateName', u'DestWac',\n",
       "       u'CRSDepTime', u'DepTime', u'DepDelay', u'DepDelayMinutes', u'DepDel15',\n",
       "       u'DepartureDelayGroups', u'DepTimeBlk', u'TaxiOut', u'WheelsOff',\n",
       "       u'WheelsOn', u'TaxiIn', u'CRSArrTime', u'ArrTime', u'ArrDelay',\n",
       "       u'ArrDelayMinutes', u'ArrDel15', u'ArrivalDelayGroups', u'ArrTimeBlk',\n",
       "       u'Cancelled', u'CancellationCode', u'CRSElapsedTime',\n",
       "       u'ActualElapsedTime', u'AirTime', u'Flights', u'Distance',\n",
       "       u'DistanceGroup', u'CarrierDelay', u'WeatherDelay', u'NASDelay',\n",
       "       u'SecurityDelay', u'LateAircraftDelay', u'FirstDepTime',\n",
       "       u'TotalAddGTime', u'LongestAddGTime', u'Carrier Name',\n",
       "       u'ArrFlightsPerCity', u'DestMarket', u'OrigMarket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check column names of second data frame\n",
    "OnTimeDataFrames[1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check that all data frames have same column names\n",
    "assert np.all(X.columns == OnTimeDataFrames[0].columns for X in OnTimeDataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Correct ExpressJet Airways issue\n",
    "for X in OnTimeDataFrames:\n",
    "    X[\"Carrier Name\"] = X[\"Carrier Name\"].replace(\"ExpressJet Airlines Inc. (1)\",\n",
    "                                                               \"ExpressJet Airlines Inc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98231, 68)\n",
      "(98163, 68)\n",
      "(98252, 68)\n",
      "(98174, 68)\n",
      "(98197, 68)\n",
      "(98184, 68)\n",
      "(98200, 68)\n",
      "(98205, 68)\n",
      "(98198, 68)\n",
      "(98190, 68)\n",
      "(98234, 68)\n",
      "(98315, 68)\n",
      "(98177, 68)\n",
      "(98145, 68)\n",
      "(88801, 68)\n"
     ]
    }
   ],
   "source": [
    "#Get rid of rows with null values for ArrDelay\n",
    "OnTimeDataNoNull = [X[np.isfinite(X.ArrDelay)] for X in OnTimeDataFrames]\n",
    "for X in OnTimeDataNoNull: print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute interactions for airlines * airports with a certain %\n",
    "def interactions_aa(X, pct):\n",
    "    #dictionary of features with percentage \"1\"s\n",
    "    PercentageDict = {}\n",
    "    for feature in X.columns:\n",
    "        PercentageDict[feature] = X[feature].mean(axis=1)\n",
    "    #calculate interactions\n",
    "    X1 = X.copy()\n",
    "    for feat_A in [name for name in X.columns if name[0] == 'C']:\n",
    "        for feat_B in [name for name in X.columns if name[0] in list('DO') and PercentageDict[name] > pct]:\n",
    "            X1[feat_A + \"*\" + feat_B] = (X1[feat_A].to_dense() * X1[feat_B].to_dense()).to_sparse()\n",
    "    return X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dummy variables\n",
    "def DummyRegressors(data):\n",
    "    #Create dummies for airline, origin and destination airports, month, and time of day\n",
    "    #Drop first column in each data frame to avoid singular matrix\n",
    "    #Also include ArrDelay variable so we don't have to grab this separately from the old data frame\n",
    "    CarrierDummies = pd.get_dummies(data[\"Carrier Name\"], prefix=\"C\", sparse=True, drop_first=True)\n",
    "    OriginDummies = pd.get_dummies(data.Origin, prefix=\"O\", sparse=True, drop_first=True)\n",
    "    DestDummies = pd.get_dummies(data.Dest, prefix=\"D\", sparse=True, drop_first=True)\n",
    "    MonthDummies = pd.get_dummies(data.Month, prefix=\"M\", sparse=True, drop_first=True)\n",
    "    TimeDummies = pd.get_dummies(data.DepTimeBlk, prefix=\"T\", sparse=True, drop_first=True)\n",
    "    ArrDelay = data.ArrDelay\n",
    "    ArrDel15 = data.ArrDel15\n",
    "    \n",
    "    return pd.concat([CarrierDummies, OriginDummies, DestDummies, MonthDummies, TimeDummies,\n",
    "                      ArrDelay, ArrDel15], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DummyTest = DummyRegressors(OnTimeDataNoNull[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DummyTest.columns[pd.isnull(DummyTest).any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create list of data frames with dummies instead of raw data\n",
    "OnTimeDummies = [DummyRegressors(X) for X in OnTimeDataNoNull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98231, 702)\n",
      "(98163, 706)\n",
      "(98252, 703)\n",
      "(98174, 703)\n",
      "(98197, 705)\n",
      "(98184, 705)\n",
      "(98200, 696)\n",
      "(98205, 707)\n",
      "(98198, 707)\n",
      "(98190, 704)\n",
      "(98234, 699)\n",
      "(98315, 698)\n",
      "(98177, 707)\n",
      "(98145, 708)\n",
      "(88801, 701)\n"
     ]
    }
   ],
   "source": [
    "for X in OnTimeDummies: print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: not all airports and airlines are in all the data frames!  This makes sense and is a drawback of reading in the data in separate frames rather than splitting it up afterward.  We need to fix it by making sure if a column name appears in one dummy frame, it appears in all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create set of dummies that appear in any data frame, so each only appears once\n",
    "#Try it the less efficient way, but this seems to work\n",
    "DummyList = []\n",
    "for X in OnTimeDummies:\n",
    "    for name in X.columns:\n",
    "        DummyList.append(name)\n",
    "DummySet = set(DummyList)\n",
    "len(DummySet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DummySet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98231 98231\n",
      "98163 98163\n",
      "98252 98252\n",
      "98174 98174\n",
      "98197 98197\n",
      "98184 98184\n",
      "98200 98200\n",
      "98205 98205\n",
      "98198 98198\n",
      "98190 98190\n",
      "98234 98234\n",
      "98315 98315\n",
      "98177 98177\n",
      "98145 98145\n",
      "88801 88801\n"
     ]
    }
   ],
   "source": [
    "#Now add dummies for all variables in set to OnTimeDummies frames\n",
    "for X in OnTimeDummies:\n",
    "    SparseZeroes = pd.SparseSeries([0 for n in range(len(X))], index=X.index)\n",
    "    print len(SparseZeroes), len(X)\n",
    "    for name in DummySet:\n",
    "        if name not in X.columns:\n",
    "            X[name] = SparseZeroes.copy()\n",
    "            if pd.isnull(X[name]).any(): print name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98231, 718)\n",
      "(98163, 718)\n",
      "(98252, 718)\n",
      "(98174, 718)\n",
      "(98197, 718)\n",
      "(98184, 718)\n",
      "(98200, 718)\n",
      "(98205, 718)\n",
      "(98198, 718)\n",
      "(98190, 718)\n",
      "(98234, 718)\n",
      "(98315, 718)\n",
      "(98177, 718)\n",
      "(98145, 718)\n",
      "(88801, 718)\n"
     ]
    }
   ],
   "source": [
    "#Now check shapes of dummy frames again\n",
    "for X in OnTimeDummies: print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create list of data frames with interactions included\n",
    "#airport threshold: 1.5% of flights\n",
    "OnTimeDummies_Inter = [interactions_aa(X, .015) for X in OnTimeDummies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98231, 1398)\n",
      "(98163, 1398)\n",
      "(98252, 1398)\n",
      "(98174, 1398)\n",
      "(98197, 1398)\n",
      "(98184, 1415)\n",
      "(98200, 1415)\n",
      "(98205, 1398)\n",
      "(98198, 1398)\n",
      "(98190, 1415)\n",
      "(98234, 1398)\n",
      "(98315, 1398)\n",
      "(98177, 1398)\n",
      "(98145, 1398)\n",
      "(88801, 1415)\n"
     ]
    }
   ],
   "source": [
    "for X in OnTimeDummies_Inter: print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1432"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Once again the number of dummies is not precisely the same between batches.  We need to do the DummySet procedure again.\n",
    "InterList = []\n",
    "for X in OnTimeDummies_Inter:\n",
    "    for name in X.columns:\n",
    "        InterList.append(name)\n",
    "InterSet = set(InterList)\n",
    "len(InterSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add interactions to all frames\n",
    "for X in OnTimeDummies_Inter:\n",
    "    SparseZeroes = pd.SparseSeries([0 for n in range(len(X))], index=X.index)\n",
    "    for name in InterSet:\n",
    "        if name not in X.columns:\n",
    "            X[name] = SparseZeroes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98231, 1432)\n",
      "(98163, 1432)\n",
      "(98252, 1432)\n",
      "(98174, 1432)\n",
      "(98197, 1432)\n",
      "(98184, 1432)\n",
      "(98200, 1432)\n",
      "(98205, 1432)\n",
      "(98198, 1432)\n",
      "(98190, 1432)\n",
      "(98234, 1432)\n",
      "(98315, 1432)\n",
      "(98177, 1432)\n",
      "(98145, 1432)\n",
      "(88801, 1432)\n"
     ]
    }
   ],
   "source": [
    "#Now check shapes again\n",
    "for X in OnTimeDummies_Inter: print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Divide each interaction data set into training and test data sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OnTime_XTrainFrames, OnTime_XTestFrames, OnTime_YTrainFrames, OnTime_YTestFrames = [], [], [], []\n",
    "for D in OnTimeDummies_Inter:\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(D.drop([\"ArrDelay\", \"ArrDel15\"], axis=1), D.ArrDelay)\n",
    "    OnTime_XTrainFrames.append(X_train)\n",
    "    OnTime_XTestFrames.append(X_test)\n",
    "    OnTime_YTrainFrames.append(Y_train)\n",
    "    OnTime_YTestFrames.append(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import modeling formulas\n",
    "from sklearn.linear_model import SGDRegressor, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"1. linear regression model using SGDRegressor, penalty = L1\"\"\"\n",
    "linear = SGDRegressor(penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "#Use SGDRegressor partial_fit function to train model on training data\n",
    "for n in range(len(OnTime_XTrainFrames)):\n",
    "    print n\n",
    "    linear.partial_fit(OnTime_XTrainFrames[n], OnTime_YTrainFrames[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-20b2888444f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Aggregate test data into one frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mOnTime_XTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOnTime_XTestFrames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[0;32m   1333\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m                        copy=copy)\n\u001b[1;32m-> 1335\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\pandas\\tools\\merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1531\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m   1532\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1533\u001b[1;33m                 copy=self.copy)\n\u001b[0m\u001b[0;32m   1534\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4816\u001b[0m     blocks = [make_block(\n\u001b[0;32m   4817\u001b[0m         \u001b[0mconcatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4818\u001b[1;33m         placement=placement) for placement, join_units in concat_plan]\n\u001b[0m\u001b[0;32m   4819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4820\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4913\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[0;32m   4914\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[1;32m-> 4915\u001b[1;33m                  for ju in join_units]\n\u001b[0m\u001b[0;32m   4916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4917\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[1;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[0;32m   5202\u001b[0m                 \u001b[1;31m# No dtype upcasting is done here, it will be performed during\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5203\u001b[0m                 \u001b[1;31m# concatenation itself.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5204\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;34m\"\"\" need to to_dense myself (and always return a ndim sized object) \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1462\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\pandas\\sparse\\array.pyc\u001b[0m in \u001b[0;36mto_dense\u001b[1;34m(self, fill)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mConvert\u001b[0m \u001b[0mSparseSeries\u001b[0m \u001b[0mto\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \"\"\"\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\pandas\\sparse\\array.pyc\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mint_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_int_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Aggregate test data into one frame\n",
    "OnTime_XTest = pd.concat(OnTime_XTestFrames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015949835940547441"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OK then, test separately in batches to start out\n",
    "linear.score(OnTime_XTestFrames[1], OnTime_YTestFrames[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019897060414090451"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.score(OnTime_XTestFrames[0], OnTime_YTestFrames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0198970604141\n",
      "1 0.0159498359405\n",
      "2 0.0184043245129\n",
      "3 0.0158138414667\n",
      "4 0.0172777173439\n",
      "5 0.013277972406\n",
      "6 0.000530028998183\n",
      "7 0.0185260261079\n",
      "8 0.0190934579301\n",
      "9 0.0149732645629\n",
      "10 0.0130594861394\n",
      "11 0.00907258241209\n",
      "12 0.0180887691068\n",
      "13 0.0125697171668\n",
      "14 0.0290951015303\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(OnTime_XTestFrames)):\n",
    "    print n, linear.score(OnTime_XTestFrames[n], OnTime_YTestFrames[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"2. Logistic regression using SGDClassifier\"\"\"\n",
    "#Training and testing sets for logistic regression\n",
    "OnTime_X2TrainFrames, OnTime_X2TestFrames, OnTime_Y2TrainFrames, OnTime_Y2TestFrames = [], [], [], []\n",
    "for D in OnTimeDummies_Inter:\n",
    "    X2_train, X2_test, Y2_train, Y2_test = train_test_split(D.drop([\"ArrDelay\", \"ArrDel15\"], axis=1), D.ArrDel15)\n",
    "    OnTime_X2TrainFrames.append(X2_train)\n",
    "    OnTime_X2TestFrames.append(X2_test)\n",
    "    OnTime_Y2TrainFrames.append(Y2_train)\n",
    "    OnTime_Y2TestFrames.append(Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = SGDClassifier(penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "classes must be passed on the first call to partial_fit.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-584bfd23c7ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOnTime_X2TrainFrames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlogistic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOnTime_X2TrainFrames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOnTime_Y2TrainFrames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[0;32m    510\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m                                  \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m                                  coef_init=None, intercept_init=None)\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     def fit(self, X, y, coef_init=None, intercept_init=None,\n",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, n_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[0m_check_partial_fit_first_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Will\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\multiclass.pyc\u001b[0m in \u001b[0;36m_check_partial_fit_first_call\u001b[1;34m(clf, classes)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \"\"\"\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'classes_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         raise ValueError(\"classes must be passed on the first call \"\n\u001b[0m\u001b[0;32m    297\u001b[0m                          \"to partial_fit.\")\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: classes must be passed on the first call to partial_fit."
     ]
    }
   ],
   "source": [
    "for n in range(len(OnTime_X2TrainFrames)):\n",
    "    print n\n",
    "    logistic.partial_fit(OnTime_X2TrainFrames[n], OnTime_Y2TrainFrames[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(len(OnTime_X2TestFrames)):\n",
    "    print n, logistic.score(OnTime_X2TestFrames[n], OnTime_Y2TestFrames[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Troubleshooting section'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Troubleshooting section\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(OnTime_X2TestFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert 'ArrDel15' in OnTimeDummies_Inter[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77149    1.0\n",
       "21963    0.0\n",
       "66500    1.0\n",
       "74508    1.0\n",
       "91746    1.0\n",
       "3913     0.0\n",
       "68835    0.0\n",
       "8560     0.0\n",
       "57478    1.0\n",
       "22020    0.0\n",
       "72718    0.0\n",
       "37120    0.0\n",
       "79858    0.0\n",
       "48332    0.0\n",
       "85077    1.0\n",
       "8038     0.0\n",
       "63570    1.0\n",
       "54874    0.0\n",
       "75667    0.0\n",
       "87074    0.0\n",
       "63797    0.0\n",
       "29908    0.0\n",
       "24787    0.0\n",
       "61158    0.0\n",
       "69268    0.0\n",
       "38383    0.0\n",
       "75015    1.0\n",
       "49974    1.0\n",
       "42611    0.0\n",
       "20727    0.0\n",
       "        ... \n",
       "79699    0.0\n",
       "6451     0.0\n",
       "90886    0.0\n",
       "24348    0.0\n",
       "76338    1.0\n",
       "95024    0.0\n",
       "78531    0.0\n",
       "54099    0.0\n",
       "60797    1.0\n",
       "10706    0.0\n",
       "74023    0.0\n",
       "61549    0.0\n",
       "47256    0.0\n",
       "28082    1.0\n",
       "29369    0.0\n",
       "20322    0.0\n",
       "77904    0.0\n",
       "56795    1.0\n",
       "5971     0.0\n",
       "14366    0.0\n",
       "75874    0.0\n",
       "84562    1.0\n",
       "57630    0.0\n",
       "35764    0.0\n",
       "61455    0.0\n",
       "76466    1.0\n",
       "9026     0.0\n",
       "73561    0.0\n",
       "88325    0.0\n",
       "76342    1.0\n",
       "Name: ArrDel15, dtype: float64\n",
       "BlockIndex\n",
       "Block locations: array([0])\n",
       "Block lengths: array([73673])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OnTime_Y2TrainFrames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
